{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bibliotecas basicas\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "from gensim.models import doc2vec\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer \n",
    "from nltk.stem.porter import PorterStemmer\n",
    "\n",
    "# Trocando diretorios para utilização dos bancos de dados e scripts\n",
    "os.chdir(\"../\")\n",
    "\n",
    "# verifica diretorio\n",
    "os.getcwd()\n",
    "\n",
    "#importa scripts\n",
    "from py_scripts.test_models_plot_roc_auc_curve import test_models_plot_roc_auc_curve\n",
    "from py_scripts.preprocessing import preprocessing\n",
    "from py_scripts.read_corpus import read_corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../mario_cesa_780_projeto_2/data/Subm3Classes.csv') #Leitura dos dados em CSV\n",
    "df_train = pd.read_csv('../mario_cesa_780_projeto_2/data/Train3Classes.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5000 entries, 0 to 4999\n",
      "Data columns (total 4 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   id          5000 non-null   int64 \n",
      " 1   tweet_text  5000 non-null   object\n",
      " 2   tweet_date  5000 non-null   object\n",
      " 3   query_used  5000 non-null   object\n",
      "dtypes: int64(1), object(3)\n",
      "memory usage: 156.4+ KB\n"
     ]
    }
   ],
   "source": [
    "#Verificando os dados gerais do dataframe\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 95000 entries, 0 to 94999\n",
      "Data columns (total 5 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   id          95000 non-null  int64 \n",
      " 1   tweet_text  95000 non-null  object\n",
      " 2   tweet_date  95000 non-null  object\n",
      " 3   sentiment   95000 non-null  int64 \n",
      " 4   query_used  95000 non-null  object\n",
      "dtypes: int64(2), object(3)\n",
      "memory usage: 3.6+ MB\n"
     ]
    }
   ],
   "source": [
    "#Verificando os dados gerais do dataframe de treino\n",
    "df_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>tweet_date</th>\n",
       "      <th>query_used</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sentiment</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>31696</td>\n",
       "      <td>31696</td>\n",
       "      <td>31696</td>\n",
       "      <td>31696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>31678</td>\n",
       "      <td>31678</td>\n",
       "      <td>31678</td>\n",
       "      <td>31678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>31626</td>\n",
       "      <td>31626</td>\n",
       "      <td>31626</td>\n",
       "      <td>31626</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              id  tweet_text  tweet_date  query_used\n",
       "sentiment                                           \n",
       "0          31696       31696       31696       31696\n",
       "1          31678       31678       31678       31678\n",
       "2          31626       31626       31626       31626"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#As classes estão equilibradas\n",
    "df_train.groupby('sentiment').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Para Theresa May, seu plano para o Brexit é a única opção https://t.co/epl39YD9bj'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#verificando alguns textos\n",
    "df_train.tweet_text[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Inicializando stemmer e lemmatizer\n",
    "stemmer = PorterStemmer()\n",
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Filtrando as palavras\n",
    "df_train[\"filtered_words\"] = df_train['tweet_text'].apply(lambda x: preprocessing(x, lemmatizer, stemmer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['theresa', 'may', 'plano', 'brexit', 'unica', 'opcao']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Verificando as palavras filtradas\n",
    "df_train.filtered_words[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reunindo as palavras\n",
    "df_train['join_words'] = df_train['filtered_words'].apply(lambda x: ' '.join(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                   rio eleg maior bancada polici historia\n",
       "1                         fiquei tao trist vi preco camera\n",
       "2                     theresa may plano brexit unica opcao\n",
       "3              caralho quero proteg danielli pote tadinhaa\n",
       "4                                       sicaetano viva cao\n",
       "                               ...                        \n",
       "94995    cuba defensor direito humano unem contra chefe...\n",
       "94996    oportunidad venha fazer part equip vaga aberta...\n",
       "94997    syoo sei significa to feliz demai amo aqui pra...\n",
       "94998                         louistsexh n conheco posta d\n",
       "94999                                                  deu\n",
       "Name: join_words, Length: 95000, dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Verificando palavras unidas\n",
    "df_train['join_words']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Função que faz uma amostra dos dados coletados, foi necessário diminuir o numero de dados devido a problemas de memória\n",
    "percent = 0.2\n",
    "df0 = (df_train[df_train.sentiment == 0].sample(n=int(df_train[df_train.sentiment == 0].shape[0]*percent), random_state=42))\n",
    "df1 = (df_train[df_train.sentiment == 1].sample(n=int(df_train[df_train.sentiment == 1].shape[0]*percent), random_state=42))\n",
    "df2 = (df_train[df_train.sentiment == 2].sample(n=int(df_train[df_train.sentiment == 2].shape[0]*percent), random_state=42))\n",
    "\n",
    "df_train_sample = pd.concat([df0, df1, df2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_sample.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Separando as variaveis\n",
    "X = df_train_sample['join_words']\n",
    "X2 = df_train_sample['filtered_words'] #Para utilizar o D2V é necessaria uma lista de strings, foi utilizada a coluna sem Join\n",
    "y = df_train_sample['sentiment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Aplicando divisão de treino e teste\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, \n",
    "                                                     y, \n",
    "                                                     test_size = 0.3, \n",
    "                                                     random_state = 42)\n",
    "\n",
    "#Aplicando divisão especifica para treino e teste de D2V \n",
    "X_train2, X_test2, y_train2, y_test2 = train_test_split(X2, \n",
    "                                                     y, \n",
    "                                                     test_size = 0.3, \n",
    "                                                     random_state = 42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Inicializa as funções\n",
    "counter = CountVectorizer()\n",
    "tfidf = TfidfVectorizer(use_idf = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ajuste dos dados as funções de BoW e TF IDF\n",
    "X_train_bow = counter.fit_transform(X_train).toarray()\n",
    "X_test_bow = counter.transform(X_test).toarray()\n",
    "\n",
    "X_train_tfidf = tfidf.fit_transform(X_train).todense()\n",
    "X_test_tfidf  = tfidf.transform(X_test).todense()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13299, 24093)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_tfidf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ajustando os dados para Doc2Vec\n",
    "train_corpus = read_corpus(X_train2)\n",
    "test_corpus = read_corpus(X_test2, tokens_only=True)\n",
    "model_doc2vec = doc2vec.Doc2Vec(vector_size=50, min_count=2, epochs=20)\n",
    "model_doc2vec.build_vocab(train_corpus)\n",
    "model_doc2vec.train(train_corpus, total_examples=model_doc2vec.corpus_count, epochs=model_doc2vec.epochs)\n",
    "X_train_d2v = np.array(list(map(model_doc2vec.infer_vector, X_train2)))\n",
    "X_test_d2v = np.array(list(map(model_doc2vec.infer_vector, X_test2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Aplicando regressão logisita em BoW\n",
    "model_logistic = LogisticRegression(max_iter=5000)\n",
    "model_logistic.fit(X_train_bow, y_train)\n",
    "y_log_predict = model_logistic.predict(X_test_bow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.73      0.72      1869\n",
      "           1       0.69      0.68      0.68      1928\n",
      "           2       0.94      0.92      0.93      1903\n",
      "\n",
      "    accuracy                           0.77      5700\n",
      "   macro avg       0.78      0.78      0.78      5700\n",
      "weighted avg       0.78      0.77      0.78      5700\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_log_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\PICHAU\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:585: FutureWarning: np.matrix usage is deprecated in 1.0 and will raise a TypeError in 1.2. Please convert to a numpy array with np.asarray. For more information see: https://numpy.org/doc/stable/reference/generated/numpy.matrix.html\n",
      "  warnings.warn(\n",
      "C:\\Users\\PICHAU\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:585: FutureWarning: np.matrix usage is deprecated in 1.0 and will raise a TypeError in 1.2. Please convert to a numpy array with np.asarray. For more information see: https://numpy.org/doc/stable/reference/generated/numpy.matrix.html\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#Aplicando regressão logistica em TF IDF\n",
    "model_logistic2 = LogisticRegression(max_iter=5000)\n",
    "model_logistic2.fit(X_train_tfidf, y_train)\n",
    "y_log_predict2 = model_logistic2.predict(X_test_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.69      0.72      1869\n",
      "           1       0.69      0.73      0.71      1928\n",
      "           2       0.91      0.94      0.93      1903\n",
      "\n",
      "    accuracy                           0.79      5700\n",
      "   macro avg       0.79      0.79      0.78      5700\n",
      "weighted avg       0.79      0.79      0.78      5700\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_log_predict2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Aplicando regressão logistica em D2V\n",
    "model_logistic3 = LogisticRegression(max_iter=5000)\n",
    "model_logistic3.fit(X_train_d2v, y_train2)\n",
    "y_log_predict3 = model_logistic3.predict(X_test_d2v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.60      0.61      1869\n",
      "           1       0.59      0.62      0.60      1928\n",
      "           2       0.79      0.77      0.78      1903\n",
      "\n",
      "    accuracy                           0.66      5700\n",
      "   macro avg       0.66      0.66      0.66      5700\n",
      "weighted avg       0.66      0.66      0.66      5700\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test2, y_log_predict3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Aplicando floresta aleatoria em BoW\n",
    "model_random  = RandomForestClassifier()\n",
    "model_random.fit(X_train_bow, y_train)\n",
    "y_random_predict = model_random.predict(X_test_bow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.71      0.69      1869\n",
      "           1       0.67      0.56      0.61      1928\n",
      "           2       0.83      0.91      0.87      1903\n",
      "\n",
      "    accuracy                           0.73      5700\n",
      "   macro avg       0.72      0.73      0.72      5700\n",
      "weighted avg       0.72      0.73      0.72      5700\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_random_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\PICHAU\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:585: FutureWarning: np.matrix usage is deprecated in 1.0 and will raise a TypeError in 1.2. Please convert to a numpy array with np.asarray. For more information see: https://numpy.org/doc/stable/reference/generated/numpy.matrix.html\n",
      "  warnings.warn(\n",
      "C:\\Users\\PICHAU\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:585: FutureWarning: np.matrix usage is deprecated in 1.0 and will raise a TypeError in 1.2. Please convert to a numpy array with np.asarray. For more information see: https://numpy.org/doc/stable/reference/generated/numpy.matrix.html\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#Aplicando floresta aleatoria em TFIDF\n",
    "model_random2  = RandomForestClassifier()\n",
    "model_random2.fit(X_train_tfidf, y_train)\n",
    "y_random_predict2 = model_random2.predict(X_test_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.70      0.70      1869\n",
      "           1       0.69      0.60      0.64      1928\n",
      "           2       0.83      0.94      0.88      1903\n",
      "\n",
      "    accuracy                           0.75      5700\n",
      "   macro avg       0.74      0.75      0.74      5700\n",
      "weighted avg       0.74      0.75      0.74      5700\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_random_predict2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Aplicando floresta aleatoria em D2V\n",
    "model_random3  = RandomForestClassifier()\n",
    "model_random3.fit(X_train_d2v, y_train)\n",
    "y_random_predict3 = model_random3.predict(X_test_d2v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.66      0.64      1869\n",
      "           1       0.60      0.59      0.59      1928\n",
      "           2       0.85      0.80      0.82      1903\n",
      "\n",
      "    accuracy                           0.68      5700\n",
      "   macro avg       0.69      0.68      0.69      5700\n",
      "weighted avg       0.69      0.68      0.69      5700\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test2, y_random_predict3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\PICHAU\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20:25:28] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    }
   ],
   "source": [
    "#Aplicando XGBoost em BoW\n",
    "model_xgboost = XGBClassifier()\n",
    "model_xgboost.fit(X_train_bow, y_train)\n",
    "y_xg_predict = model_xgboost.predict(X_test_bow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.61      0.67      1869\n",
      "           1       0.61      0.76      0.67      1928\n",
      "           2       0.92      0.84      0.88      1903\n",
      "\n",
      "    accuracy                           0.74      5700\n",
      "   macro avg       0.76      0.74      0.74      5700\n",
      "weighted avg       0.76      0.74      0.74      5700\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_xg_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\PICHAU\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20:32:05] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    }
   ],
   "source": [
    "#Aplicando XGBoost em TFIDF\n",
    "model_xgboost2 = XGBClassifier()\n",
    "model_xgboost2.fit(X_train_tfidf, y_train)\n",
    "y_xg_predict2 = model_xgboost2.predict(X_test_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.64      0.68      1869\n",
      "           1       0.62      0.74      0.67      1928\n",
      "           2       0.94      0.85      0.89      1903\n",
      "\n",
      "    accuracy                           0.74      5700\n",
      "   macro avg       0.76      0.74      0.75      5700\n",
      "weighted avg       0.76      0.74      0.75      5700\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_xg_predict2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20:36:43] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\PICHAU\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    }
   ],
   "source": [
    "#Aplicando XGBoost em D2V\n",
    "model_xgboost3 = XGBClassifier()\n",
    "model_xgboost3.fit(X_train_d2v, y_train)\n",
    "y_xg_predict3 = model_xgboost3.predict(X_test_d2v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.65      0.64      1869\n",
      "           1       0.59      0.60      0.60      1928\n",
      "           2       0.87      0.82      0.85      1903\n",
      "\n",
      "    accuracy                           0.69      5700\n",
      "   macro avg       0.70      0.69      0.69      5700\n",
      "weighted avg       0.70      0.69      0.69      5700\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test2, y_xg_predict3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "O melhor desempenho obtido foi em regrassão logística utilizando TFIDF, como demonstrado abaixo:\n",
      " \n",
      "    \n",
      "    precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.69      0.72      1869\n",
      "           1       0.69      0.73      0.71      1928\n",
      "           2       0.91      0.94      0.93      1903\n",
      "\n",
      "    accuracy                           0.79      5700\n",
      "   macro avg       0.79      0.79      0.78      5700\n",
      "weighted avg       0.79      0.79      0.78      5700\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('''\n",
    "O melhor desempenho obtido foi em regrassão logística utilizando TFIDF, como demonstrado abaixo:\n",
    " \n",
    "    \n",
    "    precision    recall  f1-score   support\n",
    "\n",
    "           0       0.75      0.69      0.72      1869\n",
    "           1       0.69      0.73      0.71      1928\n",
    "           2       0.91      0.94      0.93      1903\n",
    "\n",
    "    accuracy                           0.79      5700\n",
    "   macro avg       0.79      0.79      0.78      5700\n",
    "weighted avg       0.79      0.79      0.78      5700\n",
    "\n",
    "Não foram usados otimizadores como RandomSearch por demorarem muito a execução e não mostrarem ganho satisfatório\n",
    "''')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tratamento do dataset de submissão\n",
    "df[\"filtered_words\"] = df['tweet_text'].apply(lambda x: preprocessing(x, lemmatizer, stemmer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['analogica',\n",
       " 'correio',\n",
       " 'espera',\n",
       " 'd',\n",
       " 'so',\n",
       " 'falta',\n",
       " 'receb',\n",
       " 'dua',\n",
       " 'lent',\n",
       " 'comecar',\n",
       " 'revelar',\n",
       " 'casa']"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Verificando as palavras filtradas\n",
    "df.filtered_words[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reunindo as palavras\n",
    "df['join_words'] = df['filtered_words'].apply(lambda x: ' '.join(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       apartamento vila mariana praca monteiro santo ...\n",
       "1       fallenc brasilgameshow quero x scout dizem dou...\n",
       "2       analogica correio espera d so falta receb dua ...\n",
       "3       festa poss president stf toffoli canta legiao ...\n",
       "4       thethiagor jubsilva gscisa grupomulheri flavia...\n",
       "                              ...                        \n",
       "4995    nao nada demai apena verdad oh pronto obrigada...\n",
       "4996     veja fato fake entrevista anthoni garotinho rjtv\n",
       "4997                nattvieiira queria ver sai causa luca\n",
       "4998    assassin s creed origin enfrentando irmao ze r...\n",
       "4999    gnt conversava paramo acho mt engracado cara k...\n",
       "Name: join_words, Length: 5000, dtype: object"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Verificando as palavras unidas\n",
    "df['join_words']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Seperando os tweets a serem classificados\n",
    "X_sub = df['join_words']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ajustando os dados para a função TFIDF\n",
    "X_sub_train_tfidf = tfidf.transform(X_sub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Classificando no melhor modelo\n",
    "y_log_predict_sub = model_logistic2.predict(X_sub_train_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 0, 1, ..., 0, 2, 0], dtype=int64)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_log_predict_sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Inserindo no DataFrame\n",
    "df['sentiment'] = y_log_predict_sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       2\n",
       "1       0\n",
       "2       1\n",
       "3       2\n",
       "4       1\n",
       "       ..\n",
       "4995    1\n",
       "4996    2\n",
       "4997    0\n",
       "4998    2\n",
       "4999    0\n",
       "Name: sentiment, Length: 5000, dtype: int64"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['sentiment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Salvando DataFrame em CSV\n",
    "df.to_csv('Mario_Cesa_780_projeto_2_submissao.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "1e915f0a29dc84041eaeb02b7b1a21c440e37a87b61d44d5e84a515737dc82bc"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
